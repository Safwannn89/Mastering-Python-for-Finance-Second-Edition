{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Dow Jones Industrial Average and Its 30 Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading Dow componentms datasets from Quandl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda remove numpy -y\n",
    "!conda install numpy -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries (run this if not already installed)\n",
    "!pip install yfinance numpy pandas --upgrade\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# Define the Dow Jones component symbols, replacing 'UTX' with 'RTX'\n",
    "SYMBOLS = [\n",
    "    'AAPL', 'MMM', 'AXP', 'BA', 'CAT',\n",
    "    'CVX', 'CSCO', 'KO', 'DD', 'XOM',\n",
    "    'GS', 'HD', 'IBM', 'INTC', 'JNJ',\n",
    "    'JPM', 'MCD', 'MRK', 'MSFT', 'NKE',\n",
    "    'PFE', 'PG', 'UNH', 'RTX', 'TRV',\n",
    "    'VZ', 'V', 'WMT', 'WBA', 'DIS',\n",
    "]\n",
    "\n",
    "# Download the adjusted closing prices using yfinance\n",
    "df_components = yf.download(\n",
    "    SYMBOLS,\n",
    "    start='2017-01-01',\n",
    "    end='2017-12-31',\n",
    "    auto_adjust=True,\n",
    "    progress=False\n",
    ")['Close']\n",
    "\n",
    "# Display the first few rows to confirm it worked\n",
    "df_components.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_df_components = df_components.fillna(method='ffill')\n",
    "daily_df_components = filled_df_components.resample('24h').ffill()\n",
    "daily_df_components = daily_df_components.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading NDAQ Dataset from Alpha Vantage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Download the all-time NDAQ dataset\n",
    "\"\"\"\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "\n",
    "# Update your Alpha Vantage API key here...\n",
    "ALPHA_VANTAGE_API_KEY = 'PZ2ISG9CYY379KLI'\n",
    "\n",
    "ts = TimeSeries(key=ALPHA_VANTAGE_API_KEY, output_format='pandas')\n",
    "df, meta_data = ts.get_daily_adjusted(symbol='NDAQ', outputsize='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Prepare the dataframe\n",
    "df_dji = pd.DataFrame(df['5. adjusted close'])\n",
    "df_dji.columns = ['NDAQ']\n",
    "df_dji.index = pd.to_datetime(df_dji.index)\n",
    "\n",
    "# Trim the new dataframe and resample\n",
    "djia_2017 = pd.DataFrame(df_dji.loc['2017'])\n",
    "djia_2017 = djia_2017.resample('24h').ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying a Kernel Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Eigenvectors and Eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "fn_z_score = lambda x: (x - x.mean()) / x.std()\n",
    "\n",
    "df_z_components = daily_df_components.apply(fn_z_score)\n",
    "fitted_pca = KernelPCA().fit(df_z_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "plt.plot(fitted_pca.lambdas_)\n",
    "plt.ylabel('eigenvalues')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_weighted_avg = lambda x: x / x.sum()\n",
    "weighted_values = fn_weighted_avg(fitted_pca.lambdas_)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weighted_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_values.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstructing the Dow Index with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "kernel_pca = KernelPCA(n_components=5).fit(df_z_components)\n",
    "pca_5 = kernel_pca.transform(df_z_components)\n",
    "\n",
    "weights = fn_weighted_avg(kernel_pca.lambdas_)\n",
    "reconstructed_values = np.dot(pca_5, weights)\n",
    "\n",
    "# Combine DJIA and PCA index for comparison\n",
    "df_combined = djia_2017.copy()\n",
    "df_combined['pca_5'] = reconstructed_values\n",
    "df_combined = df_combined.apply(fn_z_score)\n",
    "df_combined.plot(figsize=(12, 8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing a time series with trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quandl\n",
    "\n",
    "QUANDL_API_KEY = 'BCzkk3NDWt7H9yjzx-DY'  # Your Quandl key here\n",
    "quandl.ApiConfig.api_key = QUANDL_API_KEY\n",
    "\n",
    "df = quandl.get(\n",
    "    'CHRIS/CME_GC1', \n",
    "    column_index=6,\n",
    "    collapse='monthly',\n",
    "    start_date='2000-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_settle = df['Settle'].resample('MS').ffill().dropna()\n",
    "\n",
    "df_rolling = df_settle.rolling(12)\n",
    "df_mean = df_rolling.mean()\n",
    "df_std = df_rolling.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(df_settle, label='Original')\n",
    "plt.plot(df_mean, label='Mean')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_std.plot(figsize=(12, 8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "result = adfuller(df_settle)\n",
    "print('ADF statistic: ',  result[0])\n",
    "print('p-value:', result[1])\n",
    "\n",
    "critical_values = result[4]\n",
    "for key, value in critical_values.items():\n",
    "    print('Critical value (%s): %.3f' % (key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a time series stationary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detrending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df_log = np.log(df_settle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log_ma= df_log.rolling(2).mean()\n",
    "df_detrend = df_log - df_log_ma\n",
    "df_detrend.dropna(inplace=True)\n",
    "\n",
    "# Mean and standard deviation of detrended data\n",
    "df_detrend_rolling = df_detrend.rolling(12)\n",
    "df_detrend_ma = df_detrend_rolling.mean()\n",
    "df_detrend_std = df_detrend_rolling.std()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(df_detrend, label='Detrended')\n",
    "plt.plot(df_detrend_ma, label='mean')\n",
    "plt.plot(df_detrend_std, label='std')\n",
    "plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "result = adfuller(df_detrend)\n",
    "print('ADF statistic: ', result[0])\n",
    "print('p-value: %.5f' % result[1])\n",
    "\n",
    "critical_values = result[4]\n",
    "for key, value in critical_values.items():\n",
    "    print('Critical value (%s): %.3f' % (key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing trend by differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log_diff = df_log.diff(periods=3).dropna()\n",
    "\n",
    "# Mean and standard deviation of differenced data\n",
    "df_diff_rolling = df_log_diff.rolling(12)\n",
    "df_diff_ma = df_diff_rolling.mean()\n",
    "df_diff_std = df_diff_rolling.std()\n",
    "\n",
    "# Plot the stationary data\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(df_log_diff, label='Differenced')\n",
    "plt.plot(df_diff_ma, label='mean')\n",
    "plt.plot(df_diff_std, label='std')\n",
    "plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "result = adfuller(df_log_diff)\n",
    "\n",
    "print('ADF statistic:', result[0])\n",
    "print('p-value: %.5f' % result[1])\n",
    "\n",
    "critical_values = result[4]\n",
    "for key, value in critical_values.items():\n",
    "    print('Critical value (%s): %.3f' % (key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonal Decomposing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "decompose_result = seasonal_decompose(df_log.dropna(), freq=12)\n",
    "\n",
    "df_trend = decompose_result.trend\n",
    "df_season = decompose_result.seasonal\n",
    "df_residual = decompose_result.resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (12, 8)\n",
    "fig = decompose_result.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log_diff = df_residual.diff().dropna()\n",
    "\n",
    "# Mean and standard deviation of differenced data\n",
    "df_diff_rolling = df_log_diff.rolling(12)\n",
    "df_diff_ma = df_diff_rolling.mean()\n",
    "df_diff_std = df_diff_rolling.std()\n",
    "\n",
    "# Plot the stationary data\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(df_log_diff, label='Differenced')\n",
    "plt.plot(df_diff_ma, label='Mean')\n",
    "plt.plot(df_diff_std, label='Std')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = adfuller(df_residual.dropna())\n",
    "\n",
    "print('ADF statistic:',  result[0])\n",
    "print('p-value: %.5f' % result[1])\n",
    "\n",
    "critical_values = result[4]\n",
    "for key, value in critical_values.items():\n",
    "    print('Critical value (%s): %.3f' % (key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting and Predicting a Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding model parameters by grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools    \n",
    "import warnings\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def arima_grid_search(dataframe, s):\n",
    "    p = d = q = range(2)\n",
    "    param_combinations = list(itertools.product(p, d, q))\n",
    "\n",
    "    lowest_aic, pdq, pdqs = None, None, None\n",
    "\n",
    "    total_iterations = 0\n",
    "    for order in param_combinations:    \n",
    "        for (p, q, d) in param_combinations:\n",
    "            seasonal_order = (p, q, d, s)\n",
    "            total_iterations += 1\n",
    "            try:\n",
    "                model = SARIMAX(df_settle, order=order, \n",
    "                    seasonal_order=seasonal_order, \n",
    "                    enforce_stationarity=False,\n",
    "                    enforce_invertibility=False,\n",
    "                    disp=False\n",
    "                )\n",
    "                model_result = model.fit(maxiter=200, disp=False)\n",
    "\n",
    "                if not lowest_aic or model_result.aic < lowest_aic:\n",
    "                    lowest_aic = model_result.aic\n",
    "                    pdq, pdqs = order, seasonal_order\n",
    "\n",
    "            except Exception as ex:\n",
    "                continue\n",
    "\n",
    "    return lowest_aic, pdq, pdqs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_aic, order, seasonal_order = arima_grid_search(df_settle, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ARIMA{}x{}'.format(order, seasonal_order))\n",
    "print('Lowest AIC: %.3f'%lowest_aic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the SARIMAX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SARIMAX(\n",
    "    df_settle,\n",
    "    order=order,\n",
    "    seasonal_order=seasonal_order,\n",
    "    enforce_stationarity=False,\n",
    "    enforce_invertibility=False,\n",
    "    disp=False\n",
    ")\n",
    "\n",
    "model_results = model.fit(maxiter=200, disp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results.plot_diagnostics(figsize=(12, 8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results.resid.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df_settle.index)\n",
    "prediction = model_results.get_prediction(\n",
    "    start=n-12*5, \n",
    "    end=n+5\n",
    ")\n",
    "prediction_ci = prediction.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prediction_ci.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "ax = df_settle['2008':].plot(label='actual')\n",
    "prediction_ci.plot(\n",
    "    ax=ax, style=['--', '--'],\n",
    "    label='predicted/forecasted')\n",
    "\n",
    "ci_index = prediction_ci.index\n",
    "lower_ci = prediction_ci.iloc[:, 0]\n",
    "upper_ci = prediction_ci.iloc[:, 1]\n",
    "\n",
    "ax.fill_between(ci_index, lower_ci, upper_ci,\n",
    "    color='r', alpha=.1)\n",
    "\n",
    "ax.set_xlabel('Time (years)')\n",
    "ax.set_ylabel('Prices')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
