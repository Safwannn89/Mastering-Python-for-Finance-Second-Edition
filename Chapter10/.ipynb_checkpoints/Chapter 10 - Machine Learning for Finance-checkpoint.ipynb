{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting prices with a single-asset regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the independent and target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - conda-forge\n",
      " - defaults\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\Lenovo\\anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - numpy=1.26.4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages: ...working... done\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "# This command will fix the corrupted numpy in your active environment\n",
    "!conda install --force-reinstall -c conda-forge numpy=1.26.4 --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starting...\n",
      "Training completed.\n",
      "Mean Absolute Error: 1.2174\n"
     ]
    }
   ],
   "source": [
    "# --- 1. SETUP AND DATA DOWNLOAD (Corrected Date Range) ---\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Define all tickers needed\n",
    "TICKERS = ['AAPL', 'JPM', 'GS', 'SPY', 'GLD', 'UUP', 'IEF']\n",
    "\n",
    "# FIX: Download data up to the end of 2019 to include the test period\n",
    "df_data = yf.download(\n",
    "    TICKERS,\n",
    "    start='2010-01-01',\n",
    "    end='2019-12-31', # Corrected end date\n",
    "    progress=False,\n",
    "    auto_adjust=True\n",
    ")['Close']\n",
    "\n",
    "# --- 2. DATA PREPARATION ---\n",
    "# Create the necessary DataFrames\n",
    "df_gs = df_data[['GS']]\n",
    "df_jpm = df_data[['JPM']]\n",
    "\n",
    "df_x = pd.DataFrame({'GS': df_gs['GS']})\n",
    "jpm_prices = df_jpm['JPM']\n",
    "\n",
    "# --- 3. MODEL TRAINING ---\n",
    "# Assuming the 'LinearRegressionModel' class is correctly defined in a previous cell\n",
    "linear_reg_model = LinearRegressionModel()\n",
    "linear_reg_model.learn(df_x, jpm_prices, start_date='2018',\n",
    "                       end_date='2019', lookback_period=20)\n",
    "\n",
    "# --- 4. PREDICTION AND ERROR CALCULATION ---\n",
    "# Get the dates from your test period\n",
    "all_dates = df_x.index\n",
    "start_date_ts = pd.to_datetime('2018-01-01')\n",
    "end_date_ts = pd.to_datetime('2019-12-31')\n",
    "# Ensure we only predict for dates where a model was trained\n",
    "dates = [d for d in all_dates if d >= start_date_ts and d <= end_date_ts and d in linear_reg_model.models]\n",
    "\n",
    "# Make predictions\n",
    "predictions = [linear_reg_model.predict(df_x, a_date) for a_date in dates]\n",
    "\n",
    "# Create the results DataFrame\n",
    "df_result = pd.DataFrame({\n",
    "    'prediction': predictions,\n",
    "    'actual': jpm_prices[dates]\n",
    "})\n",
    "\n",
    "# Calculate and print the Mean Absolute Error\n",
    "actual = df_result['actual']\n",
    "predicted = df_result['prediction']\n",
    "\n",
    "mae = mean_absolute_error(actual, predicted)\n",
    "print(f'Mean Absolute Error: {mae:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean squared error (MSE) as a risk metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(actual, predicted)\n",
    "print('mean squared error:', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explained variance score as a risk metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import explained_variance_score\n",
    "eva = explained_variance_score(actual, predicted)\n",
    "print('explained variance score:', eva)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R<sup>2</sup> as a risk metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(actual, predicted) \n",
    "print('r2 score:', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# FIX: A corrected version of the RidgeRegressionModel class to remove all warnings\n",
    "class RidgeRegressionModel(LinearRegressionModel):\n",
    "\n",
    "    def _train(self, x, y):\n",
    "        \"\"\"\n",
    "        Trains a Ridge regression model.\n",
    "        \"\"\"\n",
    "        model = Ridge()\n",
    "        # FIX: Use .to_numpy() instead of the deprecated .ravel()\n",
    "        model.fit(x, y.to_numpy())\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_reg_model = RidgeRegressionModel()\n",
    "ridge_reg_model.learn(df_x, jpm_prices, start_date='2018', \n",
    "                      end_date='2019', lookback_period=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, mean_absolute_error, \n",
    "    explained_variance_score, r2_score\n",
    ")\n",
    "def print_regression_metrics(df_result):\n",
    "    actual = list(df_result['Actual'])\n",
    "    predicted = list(df_result['Predicted'])\n",
    "    print('mean_absolute_error:', \n",
    "          mean_absolute_error(actual, predicted))\n",
    "    print('mean_squared_error:', mean_squared_error(actual, predicted))\n",
    "    print('explained_variance_score:', \n",
    "        explained_variance_score(actual, predicted))\n",
    "    print('r2_score:', r2_score(actual, predicted))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_regression_metrics(ridge_reg_model.df_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting returns with a cross-asset momentum model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# FIX: Define all tickers and download them in a single call using yfinance\n",
    "TICKERS = ['JPM', 'GS', 'SPY', 'GLD', 'UUP', 'IEF']\n",
    "\n",
    "# Download the closing price data\n",
    "df_data = yf.download(\n",
    "    TICKERS,\n",
    "    start='2010-01-01',\n",
    "    end='2019-12-31', # Use a consistent date range for all data\n",
    "    progress=False,\n",
    "    auto_adjust=True\n",
    ")['Close']\n",
    "\n",
    "# --- Create the individual DataFrames for the rest of the notebook ---\n",
    "\n",
    "df_jpm = df_data[['JPM']].rename(columns={'JPM': '4. close'})\n",
    "df_gs = df_data[['GS']].rename(columns={'GS': '4. close'})\n",
    "df_spx = df_data[['SPY']].rename(columns={'SPY': '4. close'})\n",
    "df_gld = df_data[['GLD']].rename(columns={'GLD': '4. close'})\n",
    "df_uup = df_data[['UUP']].rename(columns={'UUP': '4. close'})\n",
    "df_ief = df_data[['IEF']].rename(columns={'IEF': '4. close'})\n",
    "\n",
    "print(\"All data downloaded successfully.\")\n",
    "df_jpm.head() # Display a sample to confirm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input = pd.DataFrame({\n",
    "    'SPX_1m': df_spx['4. close'].pct_change(21),\n",
    "    'GLD_1m': df_gld['4. close'].pct_change(21),\n",
    "    'UUP_1m': df_uup['4. close'].pct_change(21),\n",
    "    'IEF_1m': df_ief['4. close'].pct_change(21),\n",
    "    'SPX_3m': df_spx['4. close'].pct_change(63),\n",
    "    'GLD_3m': df_gld['4. close'].pct_change(63),\n",
    "    'UUP_3m': df_uup['4. close'].pct_change(63),\n",
    "    'IEF_3m': df_ief['4. close'].pct_change(63)\n",
    "}).dropna()\n",
    "y_direction = (df_jpm['4. close'].pct_change() > 0).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX: Install and import the yfinance library\n",
    "!pip install yfinance\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# FIX: Define all tickers and download them in a single, efficient call\n",
    "TICKERS = ['JPM', 'GS', 'SPY', 'GLD', 'UUP', 'IEF']\n",
    "\n",
    "# Download the closing price data for all tickers at once\n",
    "df_data = yf.download(\n",
    "    TICKERS,\n",
    "    start='2010-01-01',\n",
    "    end='2019-12-31', # Use a consistent date range\n",
    "    progress=False,\n",
    "    auto_adjust=True\n",
    ")['Close']\n",
    "\n",
    "# --- Create the individual DataFrames the notebook expects ---\n",
    "# This ensures the rest of your code will work without changes.\n",
    "\n",
    "df_jpm = df_data[['JPM']].rename(columns={'JPM': '4. close'})\n",
    "df_gs  = df_data[['GS']].rename(columns={'GS': '4. close'})\n",
    "df_spx = df_data[['SPY']].rename(columns={'SPY': '4. close'})\n",
    "df_gld = df_data[['GLD']].rename(columns={'GLD': '4. close'})\n",
    "df_uup = df_data[['UUP']].rename(columns={'UUP': '4. close'})\n",
    "df_ief = df_data[['IEF']].rename(columns={'IEF': '4. close'})\n",
    "\n",
    "print(\"All required stock and ETF data has been downloaded successfully.\")\n",
    "df_jpm.head() # Display a sample to confirm it worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lagged = df_assets_1m.join(df_assets_3m)\\\n",
    "    .join(df_assets_6m)\\\n",
    "    .join(df_assets_12m)\\\n",
    "    .dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lagged.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = jpm_prices.pct_change().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_linear_model = LinearRegressionModel()\n",
    "multi_linear_model.learn(df_lagged, y, start_date='2018', \n",
    "                         end_date='2019', lookback_period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_linear_model.df_result.plot(\n",
    "    title='JPM actual versus predicted percentage returns',\n",
    "    style=['-', '--'], figsize=(12,8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_regression_metrics(multi_linear_model.df_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An ensemble of decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "class BaggingRegressorModel(LinearRegressionModel):\n",
    "    def get_model(self):\n",
    "        return BaggingRegressor(n_estimators=20, random_state=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging = BaggingRegressorModel()\n",
    "bagging.learn(df_lagged, y, start_date='2018', \n",
    "              end_date='2019', lookback_period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_regression_metrics(bagging.df_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting trends with classification-based machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_direction = y >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_direction.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = list(y_direction.unique())\n",
    "flags.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the dataset of multiple assets as input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input = df_assets_1m.join(df_assets_3m).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "class LogisticRegressionModel(LinearRegressionModel):\n",
    "    def get_model(self):\n",
    "        return LogisticRegression(solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_reg_model = LogisticRegressionModel()\n",
    "logistic_reg_model.learn(df_input, y_direction, start_date='2018', \n",
    "                         end_date='2019', lookback_period=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_reg_model.df_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Risk metrics for measuring classification-based predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "df_result = logistic_reg_model.df_result    \n",
    "actual = list(df_result['Actual'])\n",
    "predicted = list(df_result['Predicted'])\n",
    "\n",
    "matrix = confusion_matrix(actual, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplots(figsize=(12,8))\n",
    "sns.heatmap(matrix.T, square=True, annot=True, fmt='d', cbar=False, \n",
    "            xticklabels=flags, yticklabels=flags)\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('JPM percentage returns 2018');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('accuracy_score:', accuracy_score(actual, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "print('precision_score:', precision_score(actual, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "print('recall_score:', recall_score(actual, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print('f1_score:', f1_score(actual, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "class SVCModel(LogisticRegressionModel):\n",
    "    def get_model(self):\n",
    "        return SVC(C=1000, gamma='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = SVCModel()\n",
    "svc_model.learn(df_input, y_direction, start_date='2018', \n",
    "                end_date='2019', lookback_period=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = svc_model.df_result\n",
    "actual = list(df_result['Actual'])\n",
    "predicted = list(df_result['Predicted'])\n",
    "\n",
    "print('accuracy_score:', accuracy_score(actual, predicted))\n",
    "print('precision_score:', precision_score(actual, predicted))\n",
    "print('recall_score:', recall_score(actual, predicted))\n",
    "print('f1_score:', f1_score(actual, predicted))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
